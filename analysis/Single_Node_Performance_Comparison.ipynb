{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application benchmarks: single node performance comparison\n",
    "\n",
    "Comparison the single-node performance of three different application benchmarks across a variety of architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required modules for results analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.figsize'] = (12,6)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\", {\"font.family\": \"serif\"})\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../python-modules')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peak floating point performance\n",
    "\n",
    "In this section we calculate the peak floating point performance for each of the systems. CPU FLOPS are computed as\n",
    "(number of cores used) * (single precision FLOPS per cycle) * (frequency). See below for values used for the different systems. GPU FLOPS are computed as (number of GPUs used) * (GPU single precision FLOPS reference value\n",
    "[ref](https://www.nvidia.com/en-us/data-center/tesla-p100/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_fp = {}\n",
    "# Calculate CPU SP FP performance (GFLOP/s): cores * ops/cycle * freq.\n",
    "peak_fp['ARCHER'] = 24 * 16 * 2.7\n",
    "peak_fp['Peta4-Skylake'] = 32* 64 * 2.6\n",
    "peak_fp['Cirrus'] = 36 * 32 * 2.1\n",
    "peak_fp['Isambard'] = 64 * 16 * 2.2\n",
    "peak_fp['Tesseract'] = 24 * 32 * 2.1\n",
    "# Calculate CPU + GPU SP FP performance (GFLOP/s): (cores * ops/cycle * freq.) + (gpu * SP perf.)\n",
    "peak_fp['Wilkes2-GPU'] = (12 * 32 * 2.2) + (4 * 9300)\n",
    "peak_fp['JADE']  = (5 * 32 * 2.2) + (1 * 10600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peak memory performance\n",
    "We define the peak memory performance both in terms of the peak bandwidth measured using the StarSTREAM Triad benchmark (part of the HPC Challenge suite) and in terms of the number of memory channels available per socket. Note, these values are for the CPU systems only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-core memory bandwidth from StarSTREAM Triad (GB/s)\n",
    "peak_bw = {}\n",
    "peak_bw['ARCHER'] = 3.036\n",
    "peak_bw['Peta4-Skylake'] = 4.508\n",
    "peak_bw['Cirrus'] = 2.718\n",
    "peak_bw['Isambard'] = 3.461\n",
    "peak_bw['Tesseract'] = 5.181\n",
    "# Per-socket memory channels\n",
    "channels = {}\n",
    "channels['ARCHER'] = 4\n",
    "channels['Peta4-Skylake'] = 6\n",
    "channels['Cirrus'] = 4\n",
    "channels['Isambard'] = 8\n",
    "channels['Tesseract'] = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GROMACS: 1400k Atom Benchmark\n",
    "\n",
    "Details of the 1400k benchmark can be found in this repository at:  https://github.com/hpc-uk/archer-benchmarks/tree/master/apps/GROMACS\n",
    "\n",
    "Performance is measured in 'ns/day'. This is calculated by the GROMACS software itself and is read directly from the GROMACS output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from appanalysis import gromacs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "systems = ['ARCHER','Peta4-Skylake','Cirrus','Isambard','Tesseract','Wilkes2-GPU','JADE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best performance per platform comparison\n",
    "\n",
    "This section compares the best performaning configuration on a single node of each platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = {}\n",
    "notes = {}\n",
    "perf['ARCHER'] = gromacs.getperf('../apps/GROMACS/1400k-atoms/results/ARCHER/benchmark_1nodes24tasks2threads_201810051612.log')\n",
    "notes['ARCHER'] = '(24 tasks, 2 threads)'\n",
    "perf['Peta4-Skylake'] = gromacs.getperf('../apps/GROMACS/1400k-atoms/results/CSD3-Skylake/benchmark_1nodes32tasks1threads_201810030927.log')\n",
    "notes['Peta4-Skylake'] = '(32 tasks, 1 thread)'\n",
    "perf['Cirrus'] = gromacs.getperf('../apps/GROMACS/1400k-atoms/results/Cirrus/benchmark_1nodes36tasks2threads_201810022015.log')\n",
    "notes['Cirrus'] = '(36 tasks, 2 threads)'\n",
    "perf['Isambard'] = gromacs.getperf('../apps/GROMACS/1400k-atoms/results/Isambard/benchmark_1nodes128tasks2threads_201808201249.log')\n",
    "notes['Isambard'] = '(128 tasks, 2 threads)'\n",
    "perf['Tesseract'] = gromacs.getperf('../apps/GROMACS/1400k-atoms/results/Tesseract/benchmark_1nodes2threads_201810080945.log')\n",
    "notes['Tesseract'] = '(24 tasks, 2 threads)'\n",
    "perf['Wilkes2-GPU'] = gromacs.getperf('../apps/GROMACS/1400k-atoms/results/CSD3-GPU/benchmark_1nodes4rankspn4gpus_201808240945.log')\n",
    "notes['Wilkes2-GPU'] = '(4 MPI tasks, 3 OMP per task, 4 GPU)'\n",
    "#Â JADE performance result is taken from the runs by HEC BioSim\n",
    "perf['JADE'] = 1.647\n",
    "notes['JADE'] = '(5 core, 1 GPU), http://www.hecbiosim.ac.uk/jade-benchmarks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance improvement relative to ARCHER:\n",
      "\n",
      "         System  Perf. (ns/day)     Improvement\n",
      "         ======  ==============     ===========\n",
      "         ARCHER           1.216           1.000 (24 tasks, 2 threads)\n",
      "  Peta4-Skylake           2.082           1.712 (32 tasks, 1 thread)\n",
      "         Cirrus           1.699           1.397 (36 tasks, 2 threads)\n",
      "       Isambard           1.471           1.210 (128 tasks, 2 threads)\n",
      "      Tesseract           1.323           1.088 (24 tasks, 2 threads)\n",
      "    Wilkes2-GPU           2.744           2.257 (4 MPI tasks, 3 OMP per task, 4 GPU)\n",
      "           JADE           1.647           1.354 (5 core, 1 GPU), http://www.hecbiosim.ac.uk/jade-benchmarks\n"
     ]
    }
   ],
   "source": [
    "formath = \"{:>15s} {:>15s} {:>15s}\"\n",
    "formatp = \"{:>15s} {:>15.3f} {:>15.3f} {:s}\"\n",
    "print(\"Performance improvement relative to ARCHER:\\n\")\n",
    "print(formath.format('System', 'Perf. (ns/day)', 'Improvement'))\n",
    "print(formath.format('======', '==============', '==========='))\n",
    "gmx_perf_a = []\n",
    "fp_perf_a = []\n",
    "gmx_bw_a = []\n",
    "peak_bw_a = []\n",
    "channels_a = []\n",
    "for system in systems:\n",
    "    tperf = perf.get(system,0.0)\n",
    "    print(formatp.format(system, tperf, tperf/perf['ARCHER'], notes.get(system, '')))\n",
    "    if system in peak_fp:\n",
    "        gmx_perf_a.append(perf.get(system,0.0))\n",
    "        fp_perf_a.append(peak_fp.get(system,0.0))\n",
    "    if system in peak_bw:\n",
    "        gmx_bw_a.append(perf.get(system,0.0))\n",
    "        peak_bw_a.append(peak_bw.get(system,0.0))\n",
    "        channels_a.append(channels.get(system,0.0))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation to peak floating point performance\n",
    "\n",
    "Below we compute the correlation coefficients for the GROMACS benchmark performance compared to peak floating point performance. We perform two correlation tests: a Pearson correlation test to measure the correlation between numerical floating point performance and GROMACS performance; and a Spearman rank-order correlation test to measure the correlation between the order of floating point performance and GROMACS performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient =  0.881\n",
      "Spearman rank-order correlation coefficient =  0.893\n"
     ]
    }
   ],
   "source": [
    "print('Pearson correlation coefficient = ', '{:.3f}'.format(stats.pearsonr(gmx_perf_a, fp_perf_a)[0]))\n",
    "print('Spearman rank-order correlation coefficient = ', '{:.3f}'.format(stats.spearmanr(gmx_perf_a, fp_perf_a)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the Pearson and Spearman rank-order correlation coefficients are high indicating that the GROMACS benchmark performance is strongly correlated to single preciaion floating point performance of the compute resources used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation to peak memory performance\n",
    "\n",
    "Below we compute the correlation coefficients for the GROMACS benchmark performance compared to peak floating point performance. We perform two correlation tests: a Pearson correlation test to measure the correlation between numerical floating point performance and GROMACS performance; and a Spearman rank-order correlation test to measure the correlation between the order of floating point performance and GROMACS performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient =  0.130\n",
      "Spearman rank-order correlation coefficient =  0.000\n"
     ]
    }
   ],
   "source": [
    "print('Pearson correlation coefficient = ', '{:.3f}'.format(stats.pearsonr(gmx_bw_a, peak_bw_a)[0]))\n",
    "print('Spearman rank-order correlation coefficient = ', '{:.3f}'.format(stats.spearmanr(gmx_bw_a, peak_bw_a)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient =  0.099\n",
      "Spearman rank-order correlation coefficient =  0.211\n"
     ]
    }
   ],
   "source": [
    "print('Pearson correlation coefficient = ', '{:.3f}'.format(stats.pearsonr(gmx_bw_a, channels_a)[0]))\n",
    "print('Spearman rank-order correlation coefficient = ', '{:.3f}'.format(stats.spearmanr(gmx_bw_a, channels_a)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis confirms that there is no obvious correlation between the GROMACS benchmark performance and the memory performance (in terms of bandwidth or number of memory channels). This is as expected as, for this benchmark, we would not expect GROMACS to be dependent on on memory performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance comparison matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     ARCHER Peta4-Skylake        Cirrus      Isambard     Tesseract   Wilkes2-GPU          JADE\n",
      "ARCHER                1.000         0.584         0.716         0.827         0.919         0.443         0.738\n",
      "Peta4-Skylake         1.712         1.000         1.225         1.415         1.574         0.759         1.264\n",
      "Cirrus                1.397         0.816         1.000         1.155         1.284         0.619         1.032\n",
      "Isambard              1.210         0.707         0.866         1.000         1.112         0.536         0.893\n",
      "Tesseract             1.088         0.635         0.779         0.899         1.000         0.482         0.803\n",
      "Wilkes2-GPU           2.257         1.318         1.615         1.865         2.074         1.000         1.666\n",
      "JADE                  1.354         0.791         0.969         1.120         1.245         0.600         1.000\n"
     ]
    }
   ],
   "source": [
    "print(\"{:13s}\".format(''),end='')\n",
    "for jsystem in systems:\n",
    "    print(\"{:>14s}\".format(jsystem), end='')\n",
    "print()\n",
    "for isystem in systems:\n",
    "    print(\"{:13s}\".format(isystem), end='')\n",
    "    for jsystem in systems:\n",
    "        print(\"{:14.3f}\".format(perf[isystem]/perf[jsystem]), end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenSBLI: Taylor-Green Vortex 512^3 benchmark\n",
    "\n",
    "Details of the Taylor-Green Vortex 512^3 benchmark can be found in this repository at: https://github.com/hpc-uk/archer-benchmarks/tree/master/apps/OpenSBLI\n",
    "\n",
    "Performance is measured in 'interations/s'. The total runtime and number of iterations are read directly from the OpenSBLI ouptut and these are used to compute the number of iterations per second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from appanalysis import osbli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "osbli_systems = ['ARCHER','Peta4-Skylake','Cirrus','Isambard','Tesseract']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best performance per platform comparison\n",
    "\n",
    "This section compares the best performaning configuration on a single node of each platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "osbli_perf = {}\n",
    "osbli_perf['ARCHER'] = 1.0 / osbli.gettiming('../apps/OpenSBLI/TGV512ss/results/ARCHER/output_1nodes_201808020923.txt')\n",
    "osbli_perf['Peta4-Skylake'] = 1.0 / osbli.gettiming('../apps/OpenSBLI/TGV512ss/results/CSD3-Skylake/output_1nodes_201812131243.txt')\n",
    "osbli_perf['Cirrus'] = 1.0 / osbli.gettiming('../apps/OpenSBLI/TGV512ss/results/Cirrus/output_1nodes_201812201536.txt')\n",
    "osbli_perf['Isambard'] = 1.0 / osbli.gettiming('../apps/OpenSBLI/TGV512ss/results/Isambard/output_1nodes_201808020732.txt')\n",
    "osbli_perf['Tesseract'] = 1.0 / osbli.gettiming('../apps/OpenSBLI/TGV512ss/results/Tesseract/output_1nodes_201812171437.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance improvement relative to ARCHER:\n",
      "\n",
      "         System  Perf. (iter/s)     Improvement\n",
      "         ======  ==============     ===========\n",
      "         ARCHER           0.100           1.000\n",
      "  Peta4-Skylake           0.170           1.700\n",
      "         Cirrus           0.130           1.302\n",
      "       Isambard           0.178           1.777\n",
      "      Tesseract           0.097           0.971\n"
     ]
    }
   ],
   "source": [
    "formath = \"{:>15s} {:>15s} {:>15s}\"\n",
    "formatp = \"{:>15s} {:>15.3f} {:>15.3f}\"\n",
    "print(\"Performance improvement relative to ARCHER:\\n\")\n",
    "print(formath.format('System', 'Perf. (iter/s)', 'Improvement'))\n",
    "print(formath.format('======', '==============', '==========='))\n",
    "aperf = osbli_perf.get('ARCHER',0.0)\n",
    "osbli_perf_a = []\n",
    "fp_perf_a = []\n",
    "osbli_bw_a = []\n",
    "peak_bw_a = []\n",
    "channels_a = []\n",
    "for system in osbli_systems:\n",
    "    tperf = osbli_perf.get(system,0.0)\n",
    "    print(formatp.format(system, tperf, tperf/aperf))\n",
    "    if system in peak_fp:\n",
    "        osbli_perf_a.append(osbli_perf.get(system,0.0))\n",
    "        fp_perf_a.append(peak_fp.get(system,0.0))\n",
    "    if system in peak_bw:\n",
    "        osbli_bw_a.append(osbli_perf.get(system,0.0))\n",
    "        peak_bw_a.append(peak_bw.get(system,0.0))\n",
    "        channels_a.append(channels.get(system,0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation to peak floating point performance\n",
    "\n",
    "Below we compute the correlation coefficients for the GROMACS benchmark performance compared to peak floating point performance. We perform two correlation tests: a Pearson correlation test to measure the correlation between numerical floating point performance and GROMACS performance; and a Spearman rank-order correlation test to measure the correlation between the order of floating point performance and GROMACS performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient =  0.692\n",
      "Spearman rank-order correlation coefficient =  0.600\n"
     ]
    }
   ],
   "source": [
    "print('Pearson correlation coefficient = ', '{:.3f}'.format(stats.pearsonr(osbli_perf_a, fp_perf_a)[0]))\n",
    "print('Spearman rank-order correlation coefficient = ', '{:.3f}'.format(stats.spearmanr(osbli_perf_a, fp_perf_a)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates that there is no real correlation between floating point performance and OpenSBLI benchmark performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation to peak memory performance\n",
    "\n",
    "Below we compute the correlation coefficients for the OpenSBLI benchmark performance compared to memory performance, both in terms of peak bandwdth and in terms of the number of memory channels. As for the floating point correlation analysis, we perform two correlation tests: a Pearson correlation test and a Spearman rank-order correlation test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient =  -0.065\n",
      "Spearman rank-order correlation coefficient =  -0.200\n"
     ]
    }
   ],
   "source": [
    "print('Pearson correlation coefficient = ', '{:.3f}'.format(stats.pearsonr(osbli_bw_a, peak_bw_a)[0]))\n",
    "print('Spearman rank-order correlation coefficient = ', '{:.3f}'.format(stats.spearmanr(osbli_bw_a, peak_bw_a)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient =  0.651\n",
      "Spearman rank-order correlation coefficient =  0.527\n"
     ]
    }
   ],
   "source": [
    "print('Pearson correlation coefficient = ', '{:.3f}'.format(stats.pearsonr(osbli_bw_a, channels_a)[0]))\n",
    "print('Spearman rank-order correlation coefficient = ', '{:.3f}'.format(stats.spearmanr(osbli_bw_a, channels_a)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results indicate that there is no real correlation between floating point performance and OpenSBLI benchmark performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the performance data by eye compared to the number of memory channels available on the different processors it appears that if the Tesseract performance is ignored, there is good correlation. We can test this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient =  0.884\n",
      "Spearman rank-order correlation coefficient =  0.949\n"
     ]
    }
   ],
   "source": [
    "print('Pearson correlation coefficient = ', '{:.3f}'.format(stats.pearsonr(osbli_bw_a[:-1], channels_a[:-1])[0]))\n",
    "print('Spearman rank-order correlation coefficient = ', '{:.3f}'.format(stats.spearmanr(osbli_bw_a[:-1], channels_a[:-1])[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This test confirms that the Tesseract performance does not fit the pattern of performance correlated to number of memory channels. We would expect the performance of a CFD application such as OpenSBLI to be dependent on random memory access performance which, in turn, is mediated by the number of memory channels available and so this result fits this expectation (with the exception of the Tesseract performance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance comparison matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     ARCHER Peta4-Skylake        Cirrus      Isambard     Tesseract\n",
      "ARCHER                1.000         0.588         0.768         0.563         1.030\n",
      "Peta4-Skylake         1.700         1.000         1.306         0.957         1.751\n",
      "Cirrus                1.302         0.766         1.000         0.733         1.341\n",
      "Isambard              1.777         1.045         1.365         1.000         1.830\n",
      "Tesseract             0.971         0.571         0.746         0.547         1.000\n"
     ]
    }
   ],
   "source": [
    "print(\"{:13s}\".format(''),end='')\n",
    "for jsystem in osbli_systems:\n",
    "    print(\"{:>14s}\".format(jsystem), end='')\n",
    "print()\n",
    "for isystem in osbli_systems:\n",
    "    print(\"{:13s}\".format(isystem), end='')\n",
    "    iperf = osbli_perf[isystem]\n",
    "    for jsystem in osbli_systems:\n",
    "        jperf = osbli_perf[jsystem]\n",
    "        print(\"{:14.3f}\".format(iperf/jperf), end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASTEP: Al Slab benchmark\n",
    "\n",
    "Details of the Al Slab benchmark can be found in this repository at:  https://github.com/hpc-uk/archer-benchmarks/blob/master/apps/CASTEP/\n",
    "\n",
    "Performance is measured in 'mean SCF cycles per second'. This is calculated from the CASTEP output files by computing the SCF cycle times, removing the minimum and maximum value and then computing the mean of the remaining values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from appanalysis import castep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "castep_systems = ['ARCHER','Peta4-Skylake','Cirrus','Isambard','Tesseract']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best performance per platform comparison\n",
    "\n",
    "This section compares the best performaning configuration on a single node of each platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "castep_perf = {}\n",
    "castep_perf['ARCHER'] = 1.0 / castep.getmeancycle('../apps/CASTEP/al3x3/results/ARCHER/al3x3.castep.1nodes')\n",
    "castep_perf['Peta4-Skylake'] = 1.0 / castep.getmeancycle('../apps/CASTEP/al3x3/results/CSD3-Skylake/al3x3.castep.1nodes')\n",
    "castep_perf['Cirrus'] = 1.0 / castep.getmeancycle('../apps/CASTEP/al3x3/results/Cirrus/17.21_gcc620_impi17/al3x3.castep.1nodes')\n",
    "castep_perf['Isambard'] = 1.0 / castep.getmeancycle('../apps/CASTEP/al3x3/results/Isambard/al3x3.castep.1nodes_201806130634')\n",
    "castep_perf['Tesseract'] = 1.0 / castep.getmeancycle('../apps/CASTEP/al3x3/results/Tesseract/al3x3_1nodes_201808071417.castep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance improvement relative to ARCHER:\n",
      "\n",
      "         System   Perf. (scf/s)     Improvement\n",
      "         ======  ==============     ===========\n",
      "         ARCHER         0.00543           1.000\n",
      "  Peta4-Skylake         0.01641           3.023\n",
      "         Cirrus         0.01109           2.043\n",
      "       Isambard         0.00691           1.273\n",
      "      Tesseract         0.00728           1.341\n"
     ]
    }
   ],
   "source": [
    "formath = \"{:>15s} {:>15s} {:>15s}\"\n",
    "formatp = \"{:>15s} {:>15.5f} {:>15.3f}\"\n",
    "print(\"Performance improvement relative to ARCHER:\\n\")\n",
    "print(formath.format('System', 'Perf. (scf/s)', 'Improvement'))\n",
    "print(formath.format('======', '==============', '==========='))\n",
    "aperf = castep_perf.get('ARCHER',0.0)\n",
    "castep_perf_a = []\n",
    "fp_perf_a = []\n",
    "castep_bw_a = []\n",
    "peak_bw_a = []\n",
    "channels_a = []\n",
    "for system in castep_systems:\n",
    "    tperf = castep_perf.get(system,0.0)\n",
    "    print(formatp.format(system, tperf, tperf/aperf))\n",
    "    if system in peak_fp:\n",
    "        castep_perf_a.append(castep_perf.get(system,0.0))\n",
    "        fp_perf_a.append(peak_fp.get(system,0.0))\n",
    "    if system in peak_bw:\n",
    "        castep_bw_a.append(castep_perf.get(system,0.0))\n",
    "        peak_bw_a.append(peak_bw.get(system,0.0))\n",
    "        channels_a.append(channels.get(system,0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation to peak floating point performance\n",
    "\n",
    "Below we compute the correlation coefficients for the CASTEP benchmark performance compared to peak floating point performance. We perform two correlation tests: a Pearson correlation test to measure the correlation between numerical floating point performance and CASTEP performance; and a Spearman rank-order correlation test to measure the correlation between the order of floating point performance and CASTEP performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient =  0.953\n",
      "Spearman rank-order correlation coefficient =  0.900\n"
     ]
    }
   ],
   "source": [
    "print('Pearson correlation coefficient = ', '{:.3f}'.format(stats.pearsonr(castep_perf_a, fp_perf_a)[0]))\n",
    "print('Spearman rank-order correlation coefficient = ', '{:.3f}'.format(stats.spearmanr(castep_perf_a, fp_perf_a)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These analyses suggest a strong correlation between the peak floating point performance of the compute nodes and the performance of the CASTEP benchmark. The correlation for this CASTEP benchmark is stronger than the correlation for GROMACS; which is traditionally though of a pure floating point application. This is probably due to the fact that, on a single node, most of the time for this CASTEP benchmark is spent in LAPACK numerical routines which are well-optimed to exploit the maximum floating point performance from the processors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation to peak memory performance\n",
    "\n",
    "Below we compute the correlation coefficients for the CASTEP benchmark performance compared to memory performance, both in terms of peak bandwdth and in terms of the number of memory channels. As for the floating point correlation analysis, we perform two correlation tests: a Pearson correlation test and a Spearman rank-order correlation test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient =  0.223\n",
      "Spearman rank-order correlation coefficient =  0.200\n"
     ]
    }
   ],
   "source": [
    "print('Pearson correlation coefficient = ', '{:.3f}'.format(stats.pearsonr(castep_bw_a, peak_bw_a)[0]))\n",
    "print('Spearman rank-order correlation coefficient = ', '{:.3f}'.format(stats.spearmanr(castep_bw_a, peak_bw_a)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient =  -0.013\n",
      "Spearman rank-order correlation coefficient =  0.053\n"
     ]
    }
   ],
   "source": [
    "print('Pearson correlation coefficient = ', '{:.3f}'.format(stats.pearsonr(castep_bw_a, channels_a)[0]))\n",
    "print('Spearman rank-order correlation coefficient = ', '{:.3f}'.format(stats.spearmanr(castep_bw_a, channels_a)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results for memory correlation suggest there is no correlation between node memory performance and the perfomance of this CASTEP benchmark on a single node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance comparison matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     ARCHER Peta4-Skylake        Cirrus      Isambard     Tesseract\n",
      "ARCHER                1.000         0.331         0.489         0.786         0.746\n",
      "Peta4-Skylake         3.023         1.000         1.479         2.375         2.254\n",
      "Cirrus                2.043         0.676         1.000         1.605         1.524\n",
      "Isambard              1.273         0.421         0.623         1.000         0.949\n",
      "Tesseract             1.341         0.444         0.656         1.054         1.000\n"
     ]
    }
   ],
   "source": [
    "print(\"{:13s}\".format(''),end='')\n",
    "for jsystem in castep_systems:\n",
    "    print(\"{:>14s}\".format(jsystem), end='')\n",
    "print()\n",
    "for isystem in castep_systems:\n",
    "    print(\"{:13s}\".format(isystem), end='')\n",
    "    iperf = castep_perf[isystem]\n",
    "    for jsystem in castep_systems:\n",
    "        jperf = castep_perf[jsystem]\n",
    "        print(\"{:14.3f}\".format(iperf/jperf), end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
