CrayPat/X:  Version 20.09.0 Revision 430aefe03  08/13/20 20:40:23

Number of PEs (MPI ranks):   1,024
                           
Numbers of PEs per Node:       128  PEs on each of  8  Nodes
                           
Numbers of Threads per PE:       1
                           
Number of Cores per Socket:     64

Execution start time:  Sat Nov  7 11:14:50 2020

System name and speed:  nid001225  2.250 GHz (nominal)

AMD Rome       CPU  Family: 23  Model: 49  Stepping:  0

Core Performance Boost:  All 1024 PEs have CPB capability


Current path to data file:
  /lus/cls01095/work/z19/z19/aturner/benchmarks/VASP/CdTe_Hybrid-profile/vasp_ncl+pat+59108-1225s   (RTS, 8 data files)


Notes for table 1:

  This table shows functions that have significant exclusive sample
    hits, averaged across ranks.
  For further explanation, see the "General table notes" below,
    or use:  pat_report -v -O samp_profile ...

Table 1:  Profile by Function

  Samp% |      Samp |     Imb. |  Imb. | Group
        |           |     Samp | Samp% |  Function
        |           |          |       |   PE=HIDE
       
 100.0% | 513,420.8 |       -- |    -- | Total
|-------------------------------------------------------------------------
|  62.2% | 319,598.8 |       -- |    -- | MPI
||------------------------------------------------------------------------
||  38.6% | 197,994.0 | 28,010.0 | 12.4% | MPI_ALLREDUCE
||  19.4% |  99,507.4 | 13,607.6 | 12.0% | MPI_ALLTOALLV
||   1.9% |   9,737.6 | 10,993.4 | 53.1% | MPI_BCAST
||========================================================================
|  19.7% | 101,346.2 |       -- |    -- | ETC
||------------------------------------------------------------------------
||  10.2% |  52,386.6 | 56,443.4 | 51.9% | dgemv_kernel_4x4
||   1.3% |   6,426.3 |  4,742.7 | 42.5% | n2fv_12
||   1.0% |   5,015.4 |  1,331.6 | 21.0% | n2bv_12
||========================================================================
|  13.4% |  68,609.9 |       -- |    -- | USER
||------------------------------------------------------------------------
||   2.2% |  11,354.2 | 14,337.8 | 55.9% | pw_charge_trace_
||   1.4% |   6,941.6 |  4,956.4 | 41.7% | vhamil_trace_
||   1.4% |   6,934.2 |  4,045.8 | 36.9% | racc0mu_hf_
||   1.3% |   6,794.8 |  5,484.2 | 44.7% | __nonlr_MOD_rpro1_hf
||   1.3% |   6,470.2 |  4,141.8 | 39.1% | __nonlr_MOD_rpromu_hf
||========================================================================
|   2.6% |  13,455.4 |       -- |    -- | FFTW
||------------------------------------------------------------------------
||   1.0% |   5,382.7 |    537.3 |  9.1% | fftw_md5putc
||========================================================================
|   1.6% |   8,287.8 |       -- |    -- | BLAS
||------------------------------------------------------------------------
||   1.0% |   5,086.4 |    898.6 | 15.0% | dgemm_kernel_loop_mnk_a1b0_naples
|=========================================================================

Notes for table 2:

  This table shows functions that have the most significant exclusive
    time, taking the maximum time across ranks and threads.
  For further explanation, see the "General table notes" below,
    or use:  pat_report -v -O profile_max ...

Table 2:  Profile of maximum function times

  Samp% |      Samp |     Imb. |   Imb. | Function
        |           |     Samp |  Samp% |  PE=[max,min]
|--------------------------------------------------------------------------
| 100.0% | 226,004.0 | 28,010.0 |  12.4% | MPI_ALLREDUCE
||-------------------------------------------------------------------------
|| 100.0% | 226,004.0 |       -- |     -- | pe.278
||  45.0% | 101,708.0 |       -- |     -- | pe.568
||=========================================================================
|  50.0% | 113,115.0 | 13,607.6 |  12.0% | MPI_ALLTOALLV
||-------------------------------------------------------------------------
||  50.0% | 113,115.0 |       -- |     -- | pe.563
||  29.6% |  66,833.0 |       -- |     -- | pe.312
||=========================================================================
|  48.2% | 108,830.0 | 56,443.4 |  51.9% | dgemv_kernel_4x4
||-------------------------------------------------------------------------
||  48.2% | 108,830.0 |       -- |     -- | pe.640
||  17.7% |  40,084.0 |       -- |     -- | pe.291
||=========================================================================
|  11.4% |  25,692.0 | 14,337.8 |  55.9% | pw_charge_trace_
||-------------------------------------------------------------------------
||  11.4% |  25,692.0 |       -- |     -- | pe.688
||   3.7% |   8,398.0 |       -- |     -- | pe.961
||=========================================================================
|   9.2% |  20,731.0 | 10,993.4 |  53.1% | MPI_BCAST
||-------------------------------------------------------------------------
||   9.2% |  20,731.0 |       -- |     -- | pe.789
||   1.2% |   2,797.0 |       -- |     -- | pe.568
||=========================================================================
|   5.4% |  12,279.0 |  5,484.2 |  44.7% | __nonlr_MOD_rpro1_hf
||-------------------------------------------------------------------------
||   5.4% |  12,279.0 |       -- |     -- | pe.93
||   2.3% |   5,116.0 |       -- |     -- | pe.914
||=========================================================================
|   5.3% |  11,898.0 |  4,956.4 |  41.7% | vhamil_trace_
||-------------------------------------------------------------------------
||   5.3% |  11,898.0 |       -- |     -- | pe.680
||   2.5% |   5,561.0 |       -- |     -- | pe.907
||=========================================================================
|   4.9% |  11,169.0 |  4,742.7 |  42.5% | n2fv_12
||-------------------------------------------------------------------------
||   4.9% |  11,169.0 |       -- |     -- | pe.48
||   0.0% |       6.0 |       -- |     -- | pe.660
||=========================================================================
|   4.9% |  10,980.0 |  4,045.8 |  36.9% | racc0mu_hf_
||-------------------------------------------------------------------------
||   4.9% |  10,980.0 |       -- |     -- | pe.24
||   2.5% |   5,637.0 |       -- |     -- | pe.963
||=========================================================================
|   4.7% |  10,612.0 |  4,141.8 |  39.1% | __nonlr_MOD_rpromu_hf
||-------------------------------------------------------------------------
||   4.7% |  10,612.0 |       -- |     -- | pe.664
||   2.3% |   5,266.0 |       -- |     -- | pe.419
||=========================================================================
|   4.6% |  10,313.0 |  7,660.0 |  74.3% | __augfast_MOD_calc_dllmm_trans
||-------------------------------------------------------------------------
||   4.6% |  10,313.0 |       -- |     -- | pe.672
||   0.7% |   1,638.0 |       -- |     -- | pe.867
||=========================================================================
|   4.4% |   9,980.0 |  9,866.7 |  99.0% | n1fv_12
||-------------------------------------------------------------------------
||   4.4% |   9,980.0 |       -- |     -- | pe.632
||   0.0% |       0.0 |       -- |     -- | pe.1023
||=========================================================================
|   4.4% |   9,934.0 |  5,244.3 |  52.8% | MPI_BARRIER
||-------------------------------------------------------------------------
||   4.4% |   9,934.0 |       -- |     -- | pe.24
||   0.4% |     830.0 |       -- |     -- | pe.228
||=========================================================================
|   4.1% |   9,294.0 |  8,130.6 |  87.6% | openblas_dcopy_k_naples
||-------------------------------------------------------------------------
||   4.1% |   9,294.0 |       -- |     -- | pe.680
||   0.2% |     500.0 |       -- |     -- | pe.859
||=========================================================================
|   3.3% |   7,508.0 |  3,731.0 |  49.7% | MPI_REDUCE
||-------------------------------------------------------------------------
||   3.3% |   7,508.0 |       -- |     -- | pe.869
||   0.0% |      46.0 |       -- |     -- | pe.500
||=========================================================================
|   3.1% |   6,992.0 |  2,668.4 |  38.2% | map_gather_
||-------------------------------------------------------------------------
||   3.1% |   6,992.0 |       -- |     -- | pe.616
||   1.6% |   3,547.0 |       -- |     -- | pe.225
||=========================================================================
|   3.1% |   6,975.0 |  6,947.9 |  99.7% | q1fv_2
||-------------------------------------------------------------------------
||   3.1% |   6,975.0 |       -- |     -- | pe.664
||   0.0% |       0.0 |       -- |     -- | pe.1023
||=========================================================================
|   2.9% |   6,628.0 |  2,893.4 |  43.7% | dgemv_kernel_4x1
||-------------------------------------------------------------------------
||   2.9% |   6,628.0 |       -- |     -- | pe.640
||   1.3% |   2,996.0 |       -- |     -- | pe.246
||=========================================================================
|   2.8% |   6,347.0 |  1,331.6 |  21.0% | n2bv_12
||-------------------------------------------------------------------------
||   2.8% |   6,347.0 |       -- |     -- | pe.16
||   0.7% |   1,639.0 |       -- |     -- | pe.391
||=========================================================================
|   2.8% |   6,274.0 |  3,909.3 |  62.4% | eccp_nl_fock_
||-------------------------------------------------------------------------
||   2.8% |   6,274.0 |       -- |     -- | pe.512
||   0.8% |   1,747.0 |       -- |     -- | pe.638
||=========================================================================
|   2.7% |   6,106.0 |  5,912.6 |  96.9% | n2fv_6
||-------------------------------------------------------------------------
||   2.7% |   6,106.0 |       -- |     -- | pe.88
||   0.0% |       0.0 |       -- |     -- | pe.1023
||=========================================================================
|   2.7% |   6,063.0 |  1,920.9 |  31.7% | t2fv_4
||-------------------------------------------------------------------------
||   2.7% |   6,063.0 |       -- |     -- | pe.600
||   0.0% |       0.0 |       -- |     -- | pe.664
||=========================================================================
|   2.6% |   5,985.0 |    898.6 |  15.0% | dgemm_kernel_loop_mnk_a1b0_naples
||-------------------------------------------------------------------------
||   2.6% |   5,985.0 |       -- |     -- | pe.600
||   1.9% |   4,372.0 |       -- |     -- | pe.499
||=========================================================================
|   2.6% |   5,920.0 |    537.3 |   9.1% | fftw_md5putc
||-------------------------------------------------------------------------
||   2.6% |   5,920.0 |       -- |     -- | pe.429
||   2.1% |   4,846.0 |       -- |     -- | pe.827
||=========================================================================
|   2.6% |   5,878.0 |  1,779.7 |  30.3% | map_scatter_
||-------------------------------------------------------------------------
||   2.6% |   5,878.0 |       -- |     -- | pe.656
||   1.5% |   3,419.0 |       -- |     -- | pe.409
||=========================================================================
|   2.6% |   5,877.0 |  2,905.5 |  49.5% | apply_gfac_der_
||-------------------------------------------------------------------------
||   2.6% |   5,877.0 |       -- |     -- | pe.680
||   1.0% |   2,351.0 |       -- |     -- | pe.747
||=========================================================================
|   2.5% |   5,735.0 |  5,727.0 | 100.0% | n1fv_3
||-------------------------------------------------------------------------
||   2.5% |   5,735.0 |       -- |     -- | pe.112
||   0.0% |       0.0 |       -- |     -- | pe.1022
||=========================================================================
|   2.5% |   5,637.0 |  5,412.8 |  96.1% | t2fv_8
||-------------------------------------------------------------------------
||   2.5% |   5,637.0 |       -- |     -- | pe.7
||   0.0% |       0.0 |       -- |     -- | pe.1019
||=========================================================================
|   2.4% |   5,427.0 |  5,387.4 |  99.4% | t2fv_16
||-------------------------------------------------------------------------
||   2.4% |   5,427.0 |       -- |     -- | pe.112
||   0.0% |       0.0 |       -- |     -- | pe.1015
||=========================================================================
|   2.4% |   5,398.0 |  1,370.7 |  25.4% | t2bv_4
||-------------------------------------------------------------------------
||   2.4% |   5,398.0 |       -- |     -- | pe.88
||   0.0% |       0.0 |       -- |     -- | pe.612
||=========================================================================
|   2.4% |   5,398.0 |  2,699.2 |  50.1% | MPI_SEND
||-------------------------------------------------------------------------
||   2.4% |   5,398.0 |       -- |     -- | pe.544
||   0.0% |       0.0 |       -- |     -- | pe.511
||=========================================================================
|   1.8% |   4,162.0 |  4,049.4 |  97.4% | t2bv_8
||-------------------------------------------------------------------------
||   1.8% |   4,162.0 |       -- |     -- | pe.296
||   0.0% |       0.0 |       -- |     -- | pe.1023
||=========================================================================
|   1.8% |   4,089.0 |  4,012.7 |  98.2% | n1bv_12
||-------------------------------------------------------------------------
||   1.8% |   4,089.0 |       -- |     -- | pe.576
||   0.0% |       0.0 |       -- |     -- | pe.1023
||=========================================================================
|   1.8% |   3,959.0 |  3,912.5 |  98.9% | t1fv_4
||-------------------------------------------------------------------------
||   1.8% |   3,959.0 |       -- |     -- | pe.24
||   0.0% |       0.0 |       -- |     -- | pe.1021
||=========================================================================
|   1.7% |   3,828.0 |  3,824.3 | 100.0% | vsnprintf
||-------------------------------------------------------------------------
||   1.7% |   3,828.0 |       -- |     -- | pe.0
||   0.0% |       0.0 |       -- |     -- | pe.1023
||=========================================================================
|   1.6% |   3,547.0 |  3,494.6 |  98.6% | t1bv_4
||-------------------------------------------------------------------------
||   1.6% |   3,547.0 |       -- |     -- | pe.514
||   0.0% |       0.0 |       -- |     -- | pe.1023
||=========================================================================
|   1.5% |   3,463.0 |  3,439.2 |  99.4% | t1buv_4
||-------------------------------------------------------------------------
||   1.5% |   3,463.0 |       -- |     -- | pe.646
||   0.0% |       0.0 |       -- |     -- | pe.1023
||=========================================================================
|   1.5% |   3,433.0 |  3,406.3 |  99.3% | t1fuv_4
||-------------------------------------------------------------------------
||   1.5% |   3,433.0 |       -- |     -- | pe.162
||   0.0% |       0.0 |       -- |     -- | pe.1023
||=========================================================================
|   1.5% |   3,382.0 |  1,267.2 |  37.5% | add_y
||-------------------------------------------------------------------------
||   1.5% |   3,382.0 |       -- |     -- | pe.656
||   0.7% |   1,690.0 |       -- |     -- | pe.854
||=========================================================================
|   1.5% |   3,363.0 |  1,305.7 |  38.9% | __cray_dgemm_
||-------------------------------------------------------------------------
||   1.5% |   3,363.0 |       -- |     -- | pe.696
||   0.7% |   1,584.0 |       -- |     -- | pe.323
||=========================================================================
|   1.4% |   3,259.0 |  1,548.0 |  47.5% | cray_memcpy
||-------------------------------------------------------------------------
||   1.4% |   3,259.0 |       -- |     -- | pe.576
||   0.0% |      38.0 |       -- |     -- | pe.607
||=========================================================================
|   1.3% |   2,972.0 |  2,914.4 |  98.2% | n2bv_6
||-------------------------------------------------------------------------
||   1.3% |   2,972.0 |       -- |     -- | pe.296
||   0.0% |       0.0 |       -- |     -- | pe.1023
||=========================================================================
|   1.3% |   2,962.0 |  2,853.9 |  96.4% | fftw_cpy1d
||-------------------------------------------------------------------------
||   1.3% |   2,962.0 |       -- |     -- | pe.519
||   0.0% |       0.0 |       -- |     -- | pe.1012
||=========================================================================
|   1.2% |   2,710.0 |  2,694.1 |  99.5% | t2fv_2
||-------------------------------------------------------------------------
||   1.2% |   2,710.0 |       -- |     -- | pe.664
||   0.0% |       0.0 |       -- |     -- | pe.1023
||=========================================================================
|   1.2% |   2,707.0 |    338.6 |  12.5% | fftw_tensor_md5
||-------------------------------------------------------------------------
||   1.2% |   2,707.0 |       -- |     -- | pe.167
||   0.9% |   2,135.0 |       -- |     -- | pe.427
||=========================================================================
|   1.1% |   2,551.0 |  2,535.1 |  99.5% | q1bv_2
||-------------------------------------------------------------------------
||   1.1% |   2,551.0 |       -- |     -- | pe.829
||   0.0% |       0.0 |       -- |     -- | pe.1023
||=========================================================================
|   1.1% |   2,513.0 |    719.2 |  28.6% | __cray_dgemv_
||-------------------------------------------------------------------------
||   1.1% |   2,513.0 |       -- |     -- | pe.640
||   0.7% |   1,479.0 |       -- |     -- | pe.900
||=========================================================================
|   1.1% |   2,431.0 |    659.9 |  27.2% | ranmar_
||-------------------------------------------------------------------------
||   1.1% |   2,431.0 |       -- |     -- | pe.568
||   0.8% |   1,699.0 |       -- |     -- | pe.747
||=========================================================================
|   1.0% |   2,367.0 |    747.8 |  31.6% | openblas_dgemv_t_naples
||-------------------------------------------------------------------------
||   1.0% |   2,367.0 |       -- |     -- | pe.536
||   0.5% |   1,171.0 |       -- |     -- | pe.862
||=========================================================================
|   1.0% |   2,157.0 |    481.4 |  22.3% | fftw_cpy2d
||-------------------------------------------------------------------------
||   1.0% |   2,157.0 |       -- |     -- | pe.24
||   0.3% |     736.0 |       -- |     -- | pe.427
|==========================================================================

Observation:  MPI Grid Detection

    There appears to be point-to-point MPI communication in a 32 X 2 X
    16 grid pattern. The 62.2% of the total execution time spent in MPI
    functions might be reduced with a rank order that maximizes
    communication between ranks on the same node. The effect of several
    rank orders is estimated below.

    A file named MPICH_RANK_ORDER.Grid was generated along with this
    report and contains usage instructions and the Custom rank order
    from the following table.

    Rank Order    On-Node    On-Node  MPICH_RANK_REORDER_METHOD
                 Bytes/PE  Bytes/PE%  
                            of Total  
                            Bytes/PE  

        Custom  2.816e+10     81.80%  3
          Fold  2.645e+10     76.84%  2
    RoundRobin  2.623e+10     76.20%  0
           SMP  2.334e+10     67.81%  1


Observation:  Metric-Based Rank Order

    When the use of a shared resource like memory bandwidth is unbalanced
    across nodes, total execution time may be reduced with a rank order
    that improves the balance.  The metric used here for resource usage
    is: USER Samp

    For each node, the metric values for the ranks on that node are
    summed.  The maximum and average value of those sums are shown below
    for both the current rank order and a custom rank order that seeks
    to reduce the maximum value.

    A file named MPICH_RANK_ORDER.USER_Samp was generated
    along with this report and contains usage instructions and the
    Custom rank order from the following table.

       Rank    Node Reduction    Maximum  Average
      Order  Metric    in Max      Value  Value
               Imb.     Value             

    Current   4.21%            9.168e+06  8.782e+06
     Custom   0.06%    4.157%  8.787e+06  8.782e+06


Observation:  MPI Hybrid Rank Order

    A hybrid rank order has been calculated that attempts to take both
    the MPI communication and USER Samp resources into account.
    The table below shows the metric-based calculations along with the
    final on-node bytes/PE value.

    A file named MPICH_RANK_ORDER.USER_Samp_hybrid was generated
    along with this report and contains usage instructions for this
    custom rank order.

       Rank    Node Reduction    Maximum    Average  On-Node
      Order  Metric    in Max      Value      Value  Bytes/PE%
               Imb.     Value                        of Total
                                                     Bytes/PE

    Current   4.21%            9.168e+06  8.782e+06  67.81%
     Custom  21.19%   -21.54%  1.114e+07  8.782e+06  75.45%


Observation:  MPI utilization

    The time spent processing MPI communications is relatively high. 
    Functions and callsites responsible for consuming the most time can
    be found in the table generated by pat_report -O callers+src (within
    the MPI group).


Notes for table 3:

  This table shows functions, and line numbers within functions, that
    have significant exclusive sample hits, averaged across ranks.
  For further explanation, see the "General table notes" below,
    or use:  pat_report -v -O samp_profile+src ...

Table 3:  Profile by Group, Function, and Line

  Samp% |      Samp |     Imb. |  Imb. | Group
        |           |     Samp | Samp% |  Function
        |           |          |       |   Source
        |           |          |       |    Line
        |           |          |       |     PE=HIDE
       
 100.0% | 513,420.8 |       -- |    -- | Total
|--------------------------------------------------------------------------
|  62.2% | 319,598.8 |       -- |    -- | MPI
||-------------------------------------------------------------------------
||  38.6% | 197,994.0 | 28,010.0 | 12.4% | MPI_ALLREDUCE
||  19.4% |  99,507.4 | 13,607.6 | 12.0% | MPI_ALLTOALLV
||   1.9% |   9,737.6 | 10,993.4 | 53.1% | MPI_BCAST
||=========================================================================
|  19.7% | 101,346.2 |       -- |    -- | ETC
||-------------------------------------------------------------------------
||  10.2% |  52,386.6 | 56,443.4 | 51.9% | dgemv_kernel_4x4
||   1.3% |   6,426.3 |  4,742.7 | 42.5% | n2fv_12
||   1.0% |   5,015.4 |  1,331.6 | 21.0% | n2bv_12
||=========================================================================
|  13.4% |  68,609.9 |       -- |    -- | USER
||-------------------------------------------------------------------------
||   2.2% |  11,354.2 |       -- |    -- | pw_charge_trace_
3|        |           |          |       |  vasp.5.4.4.pl2/build/ncl/hamil.f90
4|   1.2% |   6,383.7 |  9,317.3 | 59.4% |   line.1519
||   1.4% |   6,941.6 |       -- |    -- | vhamil_trace_
3|        |           |          |       |  vasp.5.4.4.pl2/build/ncl/hamil.f90
||   1.4% |   6,934.2 |       -- |    -- | racc0mu_hf_
3|        |           |          |       |  vasp.5.4.4.pl2/build/ncl/nonlr.f90
4|   1.2% |   6,143.2 |  3,562.8 | 36.7% |   line.3864
||   1.3% |   6,794.8 |       -- |    -- | __nonlr_MOD_rpro1_hf
3|        |           |          |       |  vasp.5.4.4.pl2/build/ncl/nonlr.f90
4|   1.0% |   5,290.1 |  4,947.9 | 48.4% |   line.3808
||   1.3% |   6,470.2 |       -- |    -- | __nonlr_MOD_rpromu_hf
3|        |           |          |       |  vasp.5.4.4.pl2/build/ncl/nonlr.f90
4|   1.0% |   4,920.9 |  3,147.1 | 39.0% |   line.3808
||=========================================================================
|   2.6% |  13,455.4 |       -- |    -- | FFTW
||-------------------------------------------------------------------------
||   1.0% |   5,382.7 |    537.3 |  9.1% | fftw_md5putc
||=========================================================================
|   1.6% |   8,287.8 |       -- |    -- | BLAS
||-------------------------------------------------------------------------
||   1.0% |   5,086.4 |    898.6 | 15.0% | dgemm_kernel_loop_mnk_a1b0_naples
|==========================================================================

Notes for table 4:

  This table shows HW performance counter data for the whole program,
    averaged across ranks or threads, as applicable.
  For further explanation, see the "General table notes" below,
    or use:  pat_report -v -O hwpc ...

Table 4:  Program HW Performance Counter Data

PE=HIDE

  
==============================================================================
  Total
------------------------------------------------------------------------------
  Thread Time                                    5,150.863371 secs
  CORE_TO_L2_CACHEABLE_REQUEST_ACCESS_STATUS:
    LS_RD_BLK_C                   0.014G/sec   70,469,070,216 req
  L2_PREFETCH_HIT_L2              0.012G/sec   59,603,104,493 hits
  L2_PREFETCH_HIT_L3              0.012G/sec   63,431,064,287 hits
  REQUESTS_TO_L2_GROUP1:L2_HW_PF  0.037G/sec  188,776,107,448 ops
  REQUESTS_TO_L2_GROUP1:RD_BLK_X  0.008G/sec   39,353,423,833 ops
  Cache Lines PF from OffCore     0.025G/sec  129,173,002,954 lines
  Cache Lines PF from Memory      0.013G/sec   65,741,938,668 lines
  Cache Lines Requested from 
    Memory                        0.007G/sec   35,864,872,583 lines
  Write Memory Traffic GBytes     0.170G/sec           877.12 GB
  Read Memory Traffic GBytes      1.262G/sec            6,503 GB
  Memory traffic GBytes           1.433G/sec            7,380 GB
  Memory Traffic / Nominal Peak                          0.7% 
==============================================================================

Notes for table 5:

  This table show the average time and number of bytes read from each
    input file, taking the average over the number of ranks that read
    from the file.  It also shows the number of read operations, and
    average rates.
  For further explanation, see the "General table notes" below,
    or use:  pat_report -v -O read_stats ...

Table 5:  File Input Stats by Filename

 Avg Read | Avg Read |   Read Rate | Number |     Avg |   Bytes/ | File Name=!x/^/(proc|sys)/
 Time per |  MiBytes | MiBytes/sec |     of |   Reads |     Call |  PE=HIDE
   Reader |      per |             | Reader |     per |          | 
     Rank |   Reader |             |  Ranks |  Reader |          | 
          |     Rank |             |        |    Rank |          | 
|-----------------------------------------------------------------------------
| 1.113894 | 0.140442 |    0.126082 |  1,024 | 1,059.0 |   139.06 | INCAR
| 0.001189 | 0.852541 |  716.866574 |  1,024 |   112.0 | 7,981.73 | POTCAR
| 0.000804 | 0.000627 |    0.779389 |  1,024 |     2.0 |   328.50 | KPOINTS
| 0.000521 | 0.003942 |    7.568235 |  1,024 |     6.0 |   689.00 | POSCAR
| 0.000307 |       -- |    0.000000 |    512 |     1.0 |     0.00 | CHGCAR
|=============================================================================

Notes for table 6:

  This table show the average time and number of bytes written to each
    output file, taking the average over the number of ranks that
    wrote to the file.  It also shows the number of write operations,
    and average rates.
  For further explanation, see the "General table notes" below,
    or use:  pat_report -v -O write_stats ...

Table 6:  File Output Stats by Filename

      Avg |    Avg Write |   Write Rate | Number |   Avg Writes |     Bytes/ | File Name=!x/^/(proc|sys)/
    Write |  MiBytes per |  MiBytes/sec |     of |   per Writer |       Call |  PE=HIDE
 Time per |  Writer Rank |              | Writer |         Rank |            | 
   Writer |              |              |  Ranks |              |            | 
     Rank |              |              |        |              |            | 
|-----------------------------------------------------------------------------
| 8.911367 |     0.312553 |     0.035073 |  1,024 | 20,195,128.7 |       0.02 | _UnknownFile_
| 3.321665 | 4,761.138611 | 1,433.359032 |      1 |     10,456.0 | 477,468.98 | WAVECAR
| 2.447809 |   491.405952 |   200.753402 |      1 |    123,096.0 |   4,185.97 | LOCPOT
| 2.366906 |   492.244297 |   207.969548 |      1 |    123,309.0 |   4,185.87 | CHGCAR
| 1.872818 |   326.702195 |   174.444177 |      1 |     83,270.0 |   4,113.99 | CHG
| 1.031251 |   206.219700 |   199.970432 |      1 |     51,950.0 |   4,162.41 | vasprun.xml
| 0.589589 |   123.248980 |   209.042286 |      1 |     31,408.0 |   4,114.75 | PROCAR
| 0.243309 |    55.116773 |   226.529538 |      1 |     13,017.0 |   4,439.90 | DOSCAR
| 0.025262 |     0.387460 |    15.337517 |      1 |        102.0 |   3,983.15 | OUTCAR
| 0.009542 |     0.138665 |    14.532655 |  1,024 |      1,939.1 |      74.98 | /dev/infiniband/rdma_cm
| 0.001113 |     0.202075 |   181.566521 |      1 |         52.0 |   4,074.83 | EIGENVAL
| 0.000940 |     0.002562 |     2.726469 |      1 |          1.0 |   2,686.00 | XDATCAR
| 0.000778 |     0.007109 |     9.133410 |      1 |          2.0 |   3,727.00 | CONTCAR
| 0.000387 |     0.004860 |    12.573897 |      1 |         79.0 |      64.51 | stdout
| 0.000013 |     0.000092 |     7.185166 |  1,024 |          1.0 |      96.58 | stderr
|=============================================================================

Table 7:  Lustre File Information

   File Path |    Stripe | Stripe | Stripe | OST list
             |      size | offset |  count | 
-----------------------------------------------------
       INCAR | 1,048,576 |      0 |      1 | 10
 vasprun.xml | 1,048,576 |      0 |      1 | 6
      OUTCAR | 1,048,576 |      0 |      1 | 7
      CHGCAR | 1,048,576 |      0 |      1 | 5
     WAVECAR | 1,048,576 |      0 |      1 | 8
    EIGENVAL | 1,048,576 |      0 |      1 | 9
     CONTCAR | 1,048,576 |      0 |      1 | 10
      DOSCAR | 1,048,576 |      0 |      1 | 11
     OSZICAR | 1,048,576 |      0 |      1 | 0
       PCDAT | 1,048,576 |      0 |      1 | 1
     XDATCAR | 1,048,576 |      0 |      1 | 2
         CHG | 1,048,576 |      0 |      1 | 3
      REPORT | 1,048,576 |      0 |      1 | 4
      POSCAR | 1,048,576 |      0 |      1 | 9
      POTCAR | 1,048,576 |      0 |      1 | 7
     KPOINTS | 1,048,576 |      0 |      1 | 2
      LOCPOT | 1,048,576 |      0 |      1 | 11
      PROCAR | 1,048,576 |      0 |      1 | 4
=====================================================

Notes for table 8:

  This table shows energy and power usage for the nodes with the
    maximum, mean, and minimum usage, as well as the sum of usage over
    all nodes.
    Energy and power for accelerators is also shown, if applicable.
  For further explanation, see the "General table notes" below,
    or use:  pat_report -v -O program_energy ...

Table 8:  Program energy and power usage (from Cray PM)

       Node |      Node | Process Time | Node Id=[mmm]
 Energy (J) | Power (W) |              |  PE=HIDE
           
 25,314,869 | 4,914.613 | 5,150.938241 | Total
|-----------------------------------------------------
|  3,221,798 |   625.480 | 5,150.918036 | nid.1306
|  3,158,140 |   613.122 | 5,150.916513 | nid.1302
|  3,133,538 |   608.345 | 5,150.921374 | nid.1305
|=====================================================

Notes for table 9:

  This table shows values shown for HiMem calculated from information
    in the /proc/self/numa_maps files captured near the end of the
    program. It is the total size of all pages, including huge pages,
    that were actually mapped into physical memory from both private
    and shared memory segments.
  For further explanation, see the "General table notes" below,
    or use:  pat_report -v -O himem ...

Table 9:  Memory High Water Mark by Numa Node

Numanode / PE=HIDE

  
============================================================================
  numanode.0
----------------------------------------------------------------------------
  Process HiMem (MiBytes)         683.7 
  HiMem Numa Node 0 (MiBytes)     614.6 MiBytes
  HiMem Numa Node 1 (MiBytes)       9.7 MiBytes
  HiMem Numa Node 2 (MiBytes)      10.7 MiBytes
  HiMem Numa Node 3 (MiBytes)       9.6 MiBytes
  HiMem Numa Node 4 (MiBytes)       9.7 MiBytes
  HiMem Numa Node 5 (MiBytes)       9.6 MiBytes
  HiMem Numa Node 6 (MiBytes)       9.6 MiBytes
  HiMem Numa Node 7 (MiBytes)      10.1 MiBytes
============================================================================
  numanode.1
----------------------------------------------------------------------------
  Process HiMem (MiBytes)         664.3 
  HiMem Numa Node 0 (MiBytes)      11.7 MiBytes
  HiMem Numa Node 1 (MiBytes)     593.9 MiBytes
  HiMem Numa Node 2 (MiBytes)      10.3 MiBytes
  HiMem Numa Node 3 (MiBytes)       9.6 MiBytes
  HiMem Numa Node 4 (MiBytes)       9.5 MiBytes
  HiMem Numa Node 5 (MiBytes)       9.6 MiBytes
  HiMem Numa Node 6 (MiBytes)       9.6 MiBytes
  HiMem Numa Node 7 (MiBytes)      10.0 MiBytes
============================================================================
  numanode.2
----------------------------------------------------------------------------
  Process HiMem (MiBytes)         664.5 
  HiMem Numa Node 0 (MiBytes)      12.0 MiBytes
  HiMem Numa Node 1 (MiBytes)       9.5 MiBytes
  HiMem Numa Node 2 (MiBytes)     594.7 MiBytes
  HiMem Numa Node 3 (MiBytes)       9.6 MiBytes
  HiMem Numa Node 4 (MiBytes)       9.5 MiBytes
  HiMem Numa Node 5 (MiBytes)       9.5 MiBytes
  HiMem Numa Node 6 (MiBytes)       9.6 MiBytes
  HiMem Numa Node 7 (MiBytes)      10.0 MiBytes
============================================================================
  numanode.3
----------------------------------------------------------------------------
  Process HiMem (MiBytes)         663.9 
  HiMem Numa Node 0 (MiBytes)      11.6 MiBytes
  HiMem Numa Node 1 (MiBytes)       9.6 MiBytes
  HiMem Numa Node 2 (MiBytes)      10.4 MiBytes
  HiMem Numa Node 3 (MiBytes)     593.7 MiBytes
  HiMem Numa Node 4 (MiBytes)       9.5 MiBytes
  HiMem Numa Node 5 (MiBytes)       9.5 MiBytes
  HiMem Numa Node 6 (MiBytes)       9.5 MiBytes
  HiMem Numa Node 7 (MiBytes)      10.0 MiBytes
============================================================================
  numanode.4
----------------------------------------------------------------------------
  Process HiMem (MiBytes)         664.2 
  HiMem Numa Node 0 (MiBytes)      11.7 MiBytes
  HiMem Numa Node 1 (MiBytes)       9.5 MiBytes
  HiMem Numa Node 2 (MiBytes)      10.3 MiBytes
  HiMem Numa Node 3 (MiBytes)       9.6 MiBytes
  HiMem Numa Node 4 (MiBytes)     593.6 MiBytes
  HiMem Numa Node 5 (MiBytes)       9.6 MiBytes
  HiMem Numa Node 6 (MiBytes)       9.9 MiBytes
  HiMem Numa Node 7 (MiBytes)      10.0 MiBytes
============================================================================
  numanode.5
----------------------------------------------------------------------------
  Process HiMem (MiBytes)         663.9 
  HiMem Numa Node 0 (MiBytes)      11.6 MiBytes
  HiMem Numa Node 1 (MiBytes)       9.6 MiBytes
  HiMem Numa Node 2 (MiBytes)      10.3 MiBytes
  HiMem Numa Node 3 (MiBytes)       9.5 MiBytes
  HiMem Numa Node 4 (MiBytes)       9.6 MiBytes
  HiMem Numa Node 5 (MiBytes)     593.8 MiBytes
  HiMem Numa Node 6 (MiBytes)       9.5 MiBytes
  HiMem Numa Node 7 (MiBytes)      10.0 MiBytes
============================================================================
  numanode.6
----------------------------------------------------------------------------
  Process HiMem (MiBytes)         664.4 
  HiMem Numa Node 0 (MiBytes)      11.7 MiBytes
  HiMem Numa Node 1 (MiBytes)       9.5 MiBytes
  HiMem Numa Node 2 (MiBytes)      10.3 MiBytes
  HiMem Numa Node 3 (MiBytes)       9.5 MiBytes
  HiMem Numa Node 4 (MiBytes)       9.8 MiBytes
  HiMem Numa Node 5 (MiBytes)       9.5 MiBytes
  HiMem Numa Node 6 (MiBytes)     594.0 MiBytes
  HiMem Numa Node 7 (MiBytes)      10.0 MiBytes
============================================================================
  numanode.7
----------------------------------------------------------------------------
  Process HiMem (MiBytes)         664.4 
  HiMem Numa Node 0 (MiBytes)      11.7 MiBytes
  HiMem Numa Node 1 (MiBytes)       9.5 MiBytes
  HiMem Numa Node 2 (MiBytes)      10.3 MiBytes
  HiMem Numa Node 3 (MiBytes)       9.6 MiBytes
  HiMem Numa Node 4 (MiBytes)       9.5 MiBytes
  HiMem Numa Node 5 (MiBytes)       9.6 MiBytes
  HiMem Numa Node 6 (MiBytes)       9.6 MiBytes
  HiMem Numa Node 7 (MiBytes)     594.6 MiBytes
============================================================================

Notes for table 10:

  This table shows memory traffic for numa nodes, taking for each numa
    node the maximum value across nodes. It also shows the balance in
    memory traffic by showing the top 3 and bottom 3 node values.
  For further explanation, see the "General table notes" below,
    or use:  pat_report -v -O mem_bw ...

Table 10:  Memory Bandwidth by Numanode

  Memory |    Read |   Write |  Thread Time |  Memory |  Memory | Numanode
 Traffic |  Memory |  Memory |              | Traffic | Traffic |  Node Id=[max3,min3]
  GBytes | Traffic | Traffic |              |  GBytes |       / |   PE=HIDE
         |  GBytes |  GBytes |              |   / Sec | Nominal | 
         |         |         |              |         |    Peak | 
|-----------------------------------------------------------------------------
| 120,928 | 107,646 |  13,283 | 5,179.211970 |   23.35 |   11.4% | numanode.0
||----------------------------------------------------------------------------
|| 122,142 | 108,701 |  13,441 | 5,179.211970 |   23.58 |   11.5% | nid.1225
|| 120,928 | 107,646 |  13,283 | 5,159.021465 |   23.44 |   11.4% | nid.1303
|| 119,812 | 106,253 |  13,559 | 5,159.022040 |   23.22 |   11.3% | nid.1300
|| 115,221 | 102,438 |  12,783 | 5,159.022224 |   22.33 |   10.9% | nid.1305
|| 115,120 | 102,390 |  12,730 | 5,159.021207 |   22.31 |   10.9% | nid.1302
|| 114,641 | 102,048 |  12,593 | 5,159.020541 |   22.22 |   10.9% | nid.1306
||============================================================================
| 123,899 | 108,673 |  15,225 | 5,150.328726 |   24.06 |   11.7% | numanode.1
||----------------------------------------------------------------------------
|| 123,899 | 108,673 |  15,225 | 5,150.321134 |   24.06 |   11.7% | nid.1303
|| 123,410 | 108,728 |  14,681 | 5,150.320577 |   23.96 |   11.7% | nid.1225
|| 121,998 | 107,007 |  14,992 | 5,150.322413 |   23.69 |   11.6% | nid.1300
|| 118,080 | 103,696 |  14,384 | 5,150.320087 |   22.93 |   11.2% | nid.1301
|| 117,945 | 103,403 |  14,542 | 5,150.328726 |   22.90 |   11.2% | nid.1305
|| 117,227 | 103,098 |  14,129 | 5,150.320613 |   22.76 |   11.1% | nid.1306
||============================================================================
| 120,755 | 106,419 |  14,336 | 5,150.285860 |   23.45 |   11.4% | numanode.2
||----------------------------------------------------------------------------
|| 120,986 | 106,980 |  14,006 | 5,150.285860 |   23.49 |   11.5% | nid.1225
|| 120,755 | 106,419 |  14,336 | 5,150.283257 |   23.45 |   11.4% | nid.1303
|| 119,391 | 105,259 |  14,132 | 5,150.283326 |   23.18 |   11.3% | nid.1300
|| 115,656 | 101,976 |  13,680 | 5,150.283576 |   22.46 |   11.0% | nid.1301
|| 115,601 | 101,812 |  13,789 | 5,150.285694 |   22.45 |   11.0% | nid.1305
|| 114,991 | 101,250 |  13,741 | 5,150.281638 |   22.33 |   10.9% | nid.1306
||============================================================================
| 122,721 | 107,727 |  14,994 | 5,150.299153 |   23.83 |   11.6% | numanode.3
||----------------------------------------------------------------------------
|| 122,721 | 107,727 |  14,994 | 5,150.299136 |   23.83 |   11.6% | nid.1303
|| 122,027 | 107,749 |  14,277 | 5,150.298762 |   23.69 |   11.6% | nid.1225
|| 120,290 | 105,807 |  14,484 | 5,150.297913 |   23.36 |   11.4% | nid.1300
|| 117,147 | 102,804 |  14,343 | 5,150.296274 |   22.75 |   11.1% | nid.1301
|| 116,519 | 102,276 |  14,242 | 5,150.299153 |   22.62 |   11.0% | nid.1305
|| 115,777 | 102,003 |  13,774 | 5,150.295495 |   22.48 |   11.0% | nid.1306
||============================================================================
| 119,023 | 104,729 |  14,294 | 5,150.340646 |   23.11 |   11.3% | numanode.4
||----------------------------------------------------------------------------
|| 118,701 | 104,541 |  14,160 | 5,150.316406 |   23.05 |   11.3% | nid.1303
|| 118,337 | 104,843 |  13,495 | 5,150.316187 |   22.98 |   11.2% | nid.1225
|| 117,882 | 103,447 |  14,435 | 5,150.320539 |   22.89 |   11.2% | nid.1300
|| 113,513 |  99,991 |  13,523 | 5,150.317964 |   22.04 |   10.8% | nid.1301
|| 113,221 |  99,886 |  13,335 | 5,150.310761 |   21.98 |   10.7% | nid.1302
|| 112,344 |  99,130 |  13,214 | 5,150.307883 |   21.81 |   10.7% | nid.1306
||============================================================================
| 121,066 | 106,574 |  14,492 | 5,150.342247 |   23.51 |   11.5% | numanode.5
||----------------------------------------------------------------------------
|| 120,991 | 106,574 |  14,417 | 5,150.339085 |   23.49 |   11.5% | nid.1303
|| 120,605 | 106,714 |  13,891 | 5,150.337021 |   23.42 |   11.4% | nid.1225
|| 120,104 | 105,385 |  14,718 | 5,150.336529 |   23.32 |   11.4% | nid.1300
|| 115,657 | 101,812 |  13,845 | 5,150.336272 |   22.46 |   11.0% | nid.1301
|| 115,619 | 101,428 |  14,191 | 5,150.342247 |   22.45 |   11.0% | nid.1305
|| 114,849 | 101,214 |  13,635 | 5,150.341248 |   22.30 |   10.9% | nid.1306
||============================================================================
| 121,363 | 106,661 |  14,701 | 5,150.287092 |   23.56 |   11.5% | numanode.6
||----------------------------------------------------------------------------
|| 121,363 | 106,661 |  14,701 | 5,150.283931 |   23.56 |   11.5% | nid.1303
|| 120,859 | 107,079 |  13,780 | 5,150.284523 |   23.47 |   11.5% | nid.1225
|| 120,382 | 105,657 |  14,725 | 5,150.286195 |   23.37 |   11.4% | nid.1300
|| 116,013 | 101,770 |  14,243 | 5,150.287092 |   22.53 |   11.0% | nid.1305
|| 115,891 | 101,981 |  13,909 | 5,150.282542 |   22.50 |   11.0% | nid.1302
|| 114,845 | 101,364 |  13,482 | 5,150.283168 |   22.30 |   10.9% | nid.1306
||============================================================================
| 120,703 | 106,335 |  14,368 | 5,150.355116 |   23.44 |   11.4% | numanode.7
||----------------------------------------------------------------------------
|| 120,761 | 106,465 |  14,295 | 5,150.355116 |   23.45 |   11.4% | nid.1303
|| 120,587 | 106,800 |  13,787 | 5,150.352169 |   23.41 |   11.4% | nid.1225
|| 119,890 | 105,310 |  14,581 | 5,150.349445 |   23.28 |   11.4% | nid.1300
|| 115,887 | 101,810 |  14,077 | 5,150.354957 |   22.50 |   11.0% | nid.1301
|| 115,515 | 101,636 |  13,879 | 5,150.349783 |   22.43 |   11.0% | nid.1302
|| 114,682 | 101,110 |  13,572 | 5,150.351503 |   22.27 |   10.9% | nid.1306
|=============================================================================

Notes for table 11:

  This table shows total wall clock time for the ranks with the
    maximum, mean, and minimum time, as well as the average across
    ranks.
    It also shows maximum memory usage from /proc/self/numa_maps for
    those ranks, and on average.  The usage is total size of all
    pages, including huge pages, that were actually mapped into
    physical memory from both private and shared memory segments.
  For further explanation, see the "General table notes" below,
    or use:  pat_report -v -O program_time ...

Table 11:  Wall Clock Time, Memory High Water Mark

 Process Time |   Process | PE=[mmm]
              |     HiMem | 
              | (MiBytes) | 
             
 5,150.938241 |     666.7 | Total
|-----------------------------------
| 5,179.288402 |     705.7 | pe.0
| 5,150.380644 |     629.5 | pe.1012
| 5,150.234333 |     635.6 | pe.488
|===================================

========================  Additional details  ========================



General table notes:

    The default notes for a table are based on the default definition of
    the table, and do not account for the effects of command-line options
    that may modify the content of the table.
    
    Detailed notes, produced by the pat_report -v option, do account for
    all command-line options, and also show how data is aggregated, and
    if the table content is limited by thresholds, rank selections, etc.
    
    An imbalance metric in a line is based on values in main threads
    across multiple ranks, or on values across all threads, as applicable.
    
    An imbalance percent in a line is relative to the maximum value
    for that line across ranks or threads, as applicable.
    
Experiment:  samp_cs_time

Sampling interval:  10000 microsecs

Original path to data file:
  /lus/cls01095/work/z19/z19/aturner/benchmarks/VASP/CdTe_Hybrid-profile/vasp_ncl+pat+59108-1225s/xf-files   (RTS, 8 data files)

Original program:
  /lus/cls01095/work/z19/z19/aturner/software/VASP/vasp.5.4.4.pl2/bin_pat/vasp_ncl

Instrumented with:  pat_build vasp_ncl

  Option file "apa" contained:
    -Drtenv=PAT_RT_PERFCTR=default_samp
    -Drtenv=PAT_RT_EXPERIMENT=samp_cs_time
    -Drtenv=PAT_RT_SAMPLING_MODE=3
    -g upc
    -g caf
    -g mpi
    -g shmem
    -g syscall
    -g io

Instrumented program:
  /lus/cls01095/work/z19/z19/aturner/software/VASP/vasp.5.4.4.pl2/bin_pat/vasp_ncl+pat

Program invocation:
  /lus/cls01095/work/z19/z19/aturner/software/VASP/vasp.5.4.4.pl2/bin_pat/vasp_ncl+pat

Exit Status:  0 for 1,024 PEs

Memory pagesize:  4 KiB

Memory hugepagesize:  Not Available

Programming environment:  GNU

Runtime environment variables:
  CRAYPAT_LD_LIBRARY_PATH=/opt/cray/pe/gcc-libs:/opt/cray/gcc-libs:/opt/cray/pe/perftools/20.10.0/lib64
  CRAYPAT_OPTS_EXECUTABLE=libexec64/opts
  CRAYPAT_ROOT=/opt/cray/pe/perftools/20.10.0
  CRAYPE_VERSION=2.7.2
  CRAY_BINUTILS_VERSION=/opt/cray/pe/cce/10.0.4
  CRAY_CC_VERSION=10.0.4
  CRAY_FTN_VERSION=10.0.4
  CRAY_LIBSCI_VERSION=20.10.1.2
  CRAY_PERFTOOLS_VERSION=20.10.0
  LIBSCI_VERSION=20.10.1.2
  OMP_NUM_THREADS=1
  PAT_BUILD_PAPI_LIBDIR=/opt/cray/pe/papi/6.0.0.4/lib64
  PAT_REPORT_PRUNE_NAME=_cray$mt_execute_,_cray$mt_start_,_cray$mt_kmpc_fork,__cray_hwpc_,f_cray_hwpc_,cstart,hip_impl::,hipLaunchKernelGGL,__pat_,pat_region_,PAT_,OMP.slave_loop,slave_entry,_new_slave_entry,_thread_pool_slave_entry,THREAD_POOL_join,__libc_start_main,_start,__start,start_thread,__wrap_,UPC_ADIO_,_upc_,upc_,__caf_,__pgas_,syscall,__device_stub,__cray_acc_hw,_ZZ,.omp_outlined.
  PAT_RT_EXPERIMENT=samp_cs_time
  PAT_RT_PERFCTR=default_samp
  PAT_RT_SAMPLING_MODE=3
  PERFTOOLS_VERSION=20.10.0
  PMI_CONTROL_PORT=26338

Report time environment variables:
    CRAYPAT_ROOT=/opt/cray/pe/perftools/20.10.0
    PAT_REPORT_PRUNE_NAME=_cray$mt_execute_,_cray$mt_start_,_cray$mt_kmpc_fork,__cray_hwpc_,f_cray_hwpc_,cstart,hip_impl::,hipLaunchKernelGGL,__pat_,pat_region_,PAT_,OMP.slave_loop,slave_entry,_new_slave_entry,_thread_pool_slave_entry,THREAD_POOL_join,__libc_start_main,_start,__start,start_thread,__wrap_,UPC_ADIO_,_upc_,upc_,__caf_,__pgas_,syscall,__device_stub,__cray_acc_hw,_ZZ,.omp_outlined.

Number of MPI control variables collected:  94

  (To see the list, specify: -s mpi_cvar=show)

Report command line options:  <none>

Operating system:
  Linux 4.12.14-197.51_9.1.42-cray_shasta_c #1 SMP Thu Sep 10 00:55:34 UTC 2020 (abfe5b7)

Hardware performance counter events:
   CORE_TO_L2_CACHEABLE_REQUEST_ACCESS_STATUS:LS_RD_BLK_C  L2 cache request outcomes. This event does not count accesses to the L2 cache by the L2 prefetcher.:Number of data cache fill requests missing in the L2 (all types).
   L2_PREFETCH_HIT_L2                                      Number of L2 prefetcher hits in the L2
   L2_PREFETCH_HIT_L3                                      Number of L2 prefetcher hits in the L3
   REQUESTS_TO_L2_GROUP1:L2_HW_PF                          TBD:Number of prefetches accepted by L2 pipeline, hit or miss.
   REQUESTS_TO_L2_GROUP1:RD_BLK_X                          TBD:Number of data cache stores

TBD indicates that the description of the event or event modifiers was not supplied by the vendor

Warnings:
Inline regions included 1803 regions with an invalid address range, and they were ignored.

Invalid address ranges indicate a problem with data collection.

